{\rtf1\ansi\ansicpg1252\cocoartf2513
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fnil\fcharset0 Menlo-Bold;\f2\fnil\fcharset0 Menlo-Regular;
}
{\colortbl;\red255\green255\blue255;\red252\green95\blue163;\red31\green31\blue36;\red255\green255\blue255;
\red108\green121\blue134;\red208\green191\blue105;\red252\green106\blue93;}
{\*\expandedcolortbl;;\csgenericrgb\c98839\c37355\c63833;\csgenericrgb\c12054\c12284\c14131;\csgenericrgb\c100000\c100000\c100000\c85000;
\csgenericrgb\c42394\c47462\c52518;\csgenericrgb\c81498\c74939\c41233;\csgenericrgb\c98912\c41558\c36568;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 Pacman trained for 24,000 steps with the following changes:\
* limited to moves 1-4\
* 
\f1\b\fs22 \cf2 \cb3 class
\f2\b0 \cf4  PacmanClearTheBoardRewardsWrapper(gym.RewardWrapper):\
\pard\tx543\pardeftab543\pardirnatural\partightenfactor0
\cf5 # chicken gets one point for getting across the highway\cf4 \
\cf5 # in normal game, set to a higher number to encourage\cf4 \
\cf5 # safely getting across the road\cf4 \
    
\f1\b \cf2 def
\f2\b0 \cf4  __init__(self, env):\
        super(PacmanClearTheBoardRewardsWrapper, self).__init__(env)\
        
\f1\b \cf2 return
\f2\b0 \cf4  
\f1\b \cf2 None
\f2\b0 \cf4 \
        \
    
\f1\b \cf2 def
\f2\b0 \cf4  reward(self, reward):\
        
\f1\b \cf2 if
\f2\b0 \cf4  reward == \cf6 10\cf4 :\
            print(\cf7 "Reward received: "\cf4 )\
            print(reward)\
            reward = \cf6 1000\cf4 \
        
\f1\b \cf2 elif
\f2\b0 \cf4  reward == \cf6 0\cf4 :\
            reward = \cf6 -10\cf4 \
\cf5 #        elif reward > 0:\cf4 \
\cf5 #            reward = 0\cf4 \
        
\f1\b \cf2 return
\f2\b0 \cf4  reward\
\
*
\f1\b \cf2 class
\f2\b0 \cf4  FearDeathWrapper(gym.Wrapper):\
    
\f1\b \cf2 def
\f2\b0 \cf4  __init__(self, env):\
        \cf7 """Make end-of-life == end-of-episode, but only reset on true game over.\cf4 \
\cf7         Done by DeepMind for the DQN and co. since it helps value estimation.\cf4 \
\cf7         """\cf4 \
        \cf5 # Add sharp negative reward to encourage fear\cf4 \
        gym.Wrapper.__init__(self, env)\
        self.lives = \cf6 0\cf4 \
        self.was_real_done  = 
\f1\b \cf2 True
\f2\b0 \cf4 \
\
    
\f1\b \cf2 def
\f2\b0 \cf4  step(self, action):\
        obs, reward, done, info = self.env.step(action)\
        self.was_real_done = done\
        \cf5 # check current lives, make loss of life terminal,\cf4 \
        \cf5 # then update lives to handle bonus lives\cf4 \
        lives = self.env.unwrapped.ale.lives()\
        
\f1\b \cf2 if
\f2\b0 \cf4  lives < self.lives 
\f1\b \cf2 and
\f2\b0 \cf4  lives > \cf6 0\cf4 :\
            \cf5 # for Qbert sometimes we stay in lives == 0 condition for a few frames\cf4 \
            \cf5 # so it's important to keep lives > 0, so that we only reset once\cf4 \
            \cf5 # the environment advertises done.\cf4 \
            done = 
\f1\b \cf2 True
\f2\b0 \cf4 \
            reward = \cf6 -1000\cf4 \
        self.lives = lives\
        
\f1\b \cf2 return
\f2\b0 \cf4  obs, reward, done, info}